{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from glob import glob \n",
    "import os \n",
    "import random \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image \n",
    "import cv2\n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchvision.transforms as transforms \n",
    "import torchvision\n",
    "import timm \n",
    "import wandb\n",
    "\n",
    "from src.data.augmentation import *\n",
    "from src.data.factory import create_dataset,create_dataloader\n",
    "from src.options import Options\n",
    "from src.models import Model \n",
    "from src.loss_function import STPMLoss\n",
    "from src.train import AverageMeter,torch_seed,train_epoch,valid_epoch\n",
    "from src.callback import Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(cfg):\n",
    "    torch_seed(cfg['seed'])\n",
    "    \n",
    "    # build train,test loader \n",
    "    trainset,testset = create_dataset(cfg)\n",
    "    train_loader = create_dataloader(trainset,\n",
    "                                    cfg['Batchsize'],\n",
    "                                    shuffle=True)\n",
    "    test_loader = create_dataloader(testset,\n",
    "                                    cfg['Batchsize'],\n",
    "                                    shuffle=False)\n",
    "\n",
    "    # build a model, criterion and optimizer \n",
    "    model = Model(cfg['modeltype']).to(cfg['device'])\n",
    "    criterion = STPMLoss()\n",
    "    optimizer = __import__('torch.optim', fromlist='optim').__dict__['Adam'](model.parameters(), lr=cfg['lr'],betas=(cfg['beta1'],0.999))\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=cfg['nepochs'])\n",
    "    \n",
    "    print('All loaded, Training start')\n",
    "    fit(model,train_loader,test_loader,criterion,optimizer,scheduler,cfg)\n",
    "    \n",
    "def fit(model,train_loader,test_loader,criterion,optimizer,scheduler,cfg):\n",
    "    \n",
    "    callbacks = Callbacks(cfg)\n",
    "    \n",
    "    total_loss = {} \n",
    "    total_loss['train'] = [] \n",
    "    total_loss['valid'] = [] \n",
    "    \n",
    "    for epoch in range(cfg['nepochs']):\n",
    "        train_loss = train_epoch(model,train_loader,criterion,optimizer,cfg)\n",
    "        valid_loss = valid_epoch(model,test_loader,criterion,cfg)\n",
    "\n",
    "        \n",
    "        total_loss['train'].append(train_loss)\n",
    "        total_loss['valid'].append(valid_loss)\n",
    "        scheduler.step()\n",
    "        \n",
    "        log = {'Epoch' : epoch,\n",
    "               'train_loss' : train_loss,\n",
    "               'valid_loss' : valid_loss,\n",
    "               'learing_rate' : optimizer.param_groups[0]['lr']}\n",
    "        \n",
    "        #check point \n",
    "        callbacks.epoch(model,log)\n",
    "    callbacks.epoch(model,log,'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All loaded, Training start\n",
      " \n",
      "Epoch : 0\n",
      " Train loss : 3.963 | Valid loss : 4.562\n",
      "Best model saved at 0\n",
      " \n",
      "Epoch : 1\n",
      " Train loss : 2.398 | Valid loss : 4.314\n",
      "Best model saved at 1\n",
      " \n",
      "Epoch : 2\n",
      " Train loss : 1.584 | Valid loss : 4.110\n",
      "Best model saved at 2\n",
      " \n",
      "Epoch : 3\n",
      " Train loss : 1.158 | Valid loss : 3.853\n",
      "Best model saved at 3\n",
      " \n",
      "Epoch : 4\n",
      " Train loss : 0.913 | Valid loss : 3.652\n",
      "Best model saved at 4\n",
      " \n",
      "Epoch : 5\n",
      " Train loss : 0.774 | Valid loss : 3.568\n",
      "Best model saved at 5\n",
      " \n",
      "Epoch : 6\n",
      " Train loss : 0.693 | Valid loss : 3.453\n",
      "Best model saved at 6\n",
      " \n",
      "Epoch : 7\n",
      " Train loss : 0.614 | Valid loss : 3.337\n",
      "Best model saved at 7\n",
      " \n",
      "Epoch : 8\n",
      " Train loss : 0.553 | Valid loss : 3.274\n",
      "Best model saved at 8\n",
      " \n",
      "Epoch : 9\n",
      " Train loss : 0.526 | Valid loss : 3.205\n",
      "Best model saved at 9\n",
      " \n",
      "Epoch : 10\n",
      " Train loss : 0.479 | Valid loss : 3.173\n",
      "Best model saved at 10\n",
      " \n",
      "Epoch : 11\n",
      " Train loss : 0.451 | Valid loss : 3.126\n",
      "Best model saved at 11\n",
      " \n",
      "Epoch : 12\n",
      " Train loss : 0.416 | Valid loss : 3.059\n",
      "Best model saved at 12\n",
      " \n",
      "Epoch : 13\n",
      " Train loss : 0.401 | Valid loss : 3.096\n",
      " \n",
      "Epoch : 14\n",
      " Train loss : 0.385 | Valid loss : 3.049\n",
      "Best model saved at 14\n",
      " \n",
      "Epoch : 15\n",
      " Train loss : 0.382 | Valid loss : 3.005\n",
      "Best model saved at 15\n",
      " \n",
      "Epoch : 16\n",
      " Train loss : 0.361 | Valid loss : 2.995\n",
      "Best model saved at 16\n",
      " \n",
      "Epoch : 17\n",
      " Train loss : 0.362 | Valid loss : 2.960\n",
      "Best model saved at 17\n",
      " \n",
      "Epoch : 18\n",
      " Train loss : 0.344 | Valid loss : 2.949\n",
      "Best model saved at 18\n",
      " \n",
      "Epoch : 19\n",
      " Train loss : 0.335 | Valid loss : 2.946\n",
      "Best model saved at 19\n",
      " \n",
      "Epoch : 20\n",
      " Train loss : 0.336 | Valid loss : 3.031\n",
      " \n",
      "Epoch : 21\n",
      " Train loss : 0.331 | Valid loss : 2.926\n",
      "Best model saved at 21\n",
      " \n",
      "Epoch : 22\n",
      " Train loss : 0.326 | Valid loss : 3.018\n",
      " \n",
      "Epoch : 23\n",
      " Train loss : 0.322 | Valid loss : 2.881\n",
      "Best model saved at 23\n",
      " \n",
      "Epoch : 24\n",
      " Train loss : 0.306 | Valid loss : 2.873\n",
      "Best model saved at 24\n",
      " \n",
      "Epoch : 25\n",
      " Train loss : 0.306 | Valid loss : 2.862\n",
      "Best model saved at 25\n",
      " \n",
      "Epoch : 26\n",
      " Train loss : 0.300 | Valid loss : 2.827\n",
      "Best model saved at 26\n",
      " \n",
      "Epoch : 27\n",
      " Train loss : 0.305 | Valid loss : 2.871\n",
      " \n",
      "Epoch : 28\n",
      " Train loss : 0.300 | Valid loss : 2.805\n",
      "Best model saved at 28\n",
      " \n",
      "Epoch : 29\n",
      " Train loss : 0.294 | Valid loss : 2.808\n",
      " \n",
      "Epoch : 30\n",
      " Train loss : 0.291 | Valid loss : 2.813\n",
      " \n",
      "Epoch : 31\n",
      " Train loss : 0.284 | Valid loss : 2.796\n",
      "Best model saved at 31\n",
      " \n",
      "Epoch : 32\n",
      " Train loss : 0.281 | Valid loss : 2.785\n",
      "Best model saved at 32\n",
      " \n",
      "Epoch : 33\n",
      " Train loss : 0.286 | Valid loss : 2.783\n",
      "Best model saved at 33\n",
      " \n",
      "Epoch : 34\n",
      " Train loss : 0.289 | Valid loss : 2.764\n",
      "Best model saved at 34\n",
      " \n",
      "Epoch : 35\n",
      " Train loss : 0.279 | Valid loss : 2.752\n",
      "Best model saved at 35\n",
      " \n",
      "Epoch : 36\n",
      " Train loss : 0.275 | Valid loss : 2.738\n",
      "Best model saved at 36\n",
      " \n",
      "Epoch : 37\n",
      " Train loss : 0.276 | Valid loss : 2.735\n",
      "Best model saved at 37\n",
      " \n",
      "Epoch : 38\n",
      " Train loss : 0.275 | Valid loss : 2.726\n",
      "Best model saved at 38\n",
      " \n",
      "Epoch : 39\n",
      " Train loss : 0.280 | Valid loss : 2.736\n",
      " \n",
      "Epoch : 40\n",
      " Train loss : 0.270 | Valid loss : 2.693\n",
      "Best model saved at 40\n",
      " \n",
      "Epoch : 41\n",
      " Train loss : 0.274 | Valid loss : 2.682\n",
      "Best model saved at 41\n",
      " \n",
      "Epoch : 42\n",
      " Train loss : 0.272 | Valid loss : 2.675\n",
      "Best model saved at 42\n",
      " \n",
      "Epoch : 43\n",
      " Train loss : 0.276 | Valid loss : 2.741\n",
      " \n",
      "Epoch : 44\n",
      " Train loss : 0.274 | Valid loss : 2.695\n",
      " \n",
      "Epoch : 45\n",
      " Train loss : 0.271 | Valid loss : 2.687\n",
      " \n",
      "Epoch : 46\n",
      " Train loss : 0.271 | Valid loss : 2.656\n",
      "Best model saved at 46\n",
      " \n",
      "Epoch : 47\n",
      " Train loss : 0.268 | Valid loss : 2.662\n",
      " \n",
      "Epoch : 48\n",
      " Train loss : 0.267 | Valid loss : 2.628\n",
      "Best model saved at 48\n",
      " \n",
      "Epoch : 49\n",
      " Train loss : 0.263 | Valid loss : 2.649\n",
      " \n",
      "Epoch : 50\n",
      " Train loss : 0.270 | Valid loss : 2.647\n",
      " \n",
      "Epoch : 51\n",
      " Train loss : 0.258 | Valid loss : 2.655\n",
      " \n",
      "Epoch : 52\n",
      " Train loss : 0.259 | Valid loss : 2.659\n",
      " \n",
      "Epoch : 53\n",
      " Train loss : 0.257 | Valid loss : 2.607\n",
      "Best model saved at 53\n",
      " \n",
      "Epoch : 54\n",
      " Train loss : 0.265 | Valid loss : 2.647\n",
      " \n",
      "Epoch : 55\n",
      " Train loss : 0.264 | Valid loss : 2.662\n",
      " \n",
      "Epoch : 56\n",
      " Train loss : 0.266 | Valid loss : 2.632\n",
      " \n",
      "Epoch : 57\n",
      " Train loss : 0.267 | Valid loss : 2.653\n",
      " \n",
      "Epoch : 58\n",
      " Train loss : 0.258 | Valid loss : 2.639\n",
      " \n",
      "Epoch : 59\n",
      " Train loss : 0.257 | Valid loss : 2.637\n",
      " \n",
      "Epoch : 60\n",
      " Train loss : 0.252 | Valid loss : 2.628\n",
      " \n",
      "Epoch : 61\n",
      " Train loss : 0.253 | Valid loss : 2.649\n",
      " \n",
      "Epoch : 62\n",
      " Train loss : 0.252 | Valid loss : 2.613\n",
      " \n",
      "Epoch : 63\n",
      " Train loss : 0.253 | Valid loss : 2.613\n",
      " \n",
      "Epoch : 64\n",
      " Train loss : 0.251 | Valid loss : 2.624\n",
      " \n",
      "Epoch : 65\n",
      " Train loss : 0.252 | Valid loss : 2.615\n",
      " \n",
      "Epoch : 66\n",
      " Train loss : 0.254 | Valid loss : 2.615\n",
      " \n",
      "Epoch : 67\n",
      " Train loss : 0.255 | Valid loss : 2.626\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[86], line 76\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     73\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mCosineAnnealingLR(optimizer,T_max\u001b[38;5;241m=\u001b[39mcfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnepochs\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll loaded, Training start\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[87], line 11\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, scheduler, cfg)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     10\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_epoch(model,train_loader,criterion,optimizer,cfg)\n\u001b[0;32m---> 11\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m \u001b[43mvalid_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     total_loss[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     15\u001b[0m     total_loss[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(valid_loss)\n",
      "File \u001b[0;32m/Volume/MSFI_AD/src/train.py:56\u001b[0m, in \u001b[0;36mvalid_epoch\u001b[0;34m(model, test_loader, criterion, cfg)\u001b[0m\n\u001b[1;32m     53\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     54\u001b[0m valid_loss \u001b[38;5;241m=\u001b[39m AverageMeter()\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_imgs,_ \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# predict \u001b[39;00m\n\u001b[1;32m     58\u001b[0m     batch_imgs \u001b[38;5;241m=\u001b[39m batch_imgs\u001b[38;5;241m.\u001b[39mto(cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     59\u001b[0m     t_features, s_features \u001b[38;5;241m=\u001b[39m model(batch_imgs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/Volume/MSFI_AD/src/data/factory.py:107\u001b[0m, in \u001b[0;36mVisaDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    104\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dirs[idx]\n\u001b[1;32m    105\u001b[0m msk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsk_dirs[idx]\n\u001b[0;32m--> 107\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m msk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_msk(msk)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img,msk\n",
      "File \u001b[0;32m/Volume/MSFI_AD/src/data/factory.py:91\u001b[0m, in \u001b[0;36mVisaDataset.load_img\u001b[0;34m(self, img_dir)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_img\u001b[39m(\u001b[38;5;28mself\u001b[39m,img_dir):\n\u001b[1;32m     90\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot,img_dir))\n\u001b[0;32m---> 91\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:172\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    170\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cfg = Options().to_dict()            \n",
    "run(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
